# -*- coding: utf-8 -*-
"""
Effort-Dashboard - å·¥æ•°ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¸ãƒ»åˆ†æãƒ„ãƒ¼ãƒ«

è¤‡æ•°ã®æœˆæ¬¡å·¥æ•°ãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ¼ã‚¸ã—ã€æ§˜ã€…ãªè¦–ç‚¹ã‹ã‚‰åˆ†æãƒ»å¯è¦–åŒ–ã™ã‚‹
"""

import streamlit as st
import pandas as pd
import io
import os
from datetime import datetime
from utils.data_merger import process_multiple_monthly_files
from utils.visualization import (
    filter_data_by_period,
    get_available_business_content_columns,
    sort_with_config
)

try:
    from utils.visualization import create_chart_data_table
except ImportError:
    def create_chart_data_table(df, x_field, group_field, x_axis_label, grouping_label):
        """
        Fallback implementation for Streamlit Cloud deployments that still use
        an older utils.visualization module without create_chart_data_table.
        """
        if x_field == group_field:
            agg_data = (
                df.groupby([x_field])['ä½œæ¥­æ™‚é–“(h)']
                .sum()
                .reset_index()
            )

            if x_field == 'å¹´æœˆ':
                x_values = sorted(agg_data[x_field].unique().tolist())
            else:
                x_values = sort_with_config(agg_data[x_field].dropna().unique().tolist(), x_field)

            agg_data[x_field] = pd.Categorical(agg_data[x_field], categories=x_values, ordered=True)
            agg_data = agg_data.sort_values(x_field).set_index(x_field)
            agg_data.index.name = x_axis_label
            agg_data.columns = ['ä½œæ¥­æ™‚é–“[h]']
            return agg_data.map(lambda x: f"{x:.1f}")

        agg_data = (
            df.groupby([x_field, group_field])['ä½œæ¥­æ™‚é–“(h)']
            .sum()
            .reset_index()
        )

        if x_field == 'å¹´æœˆ':
            x_values = sorted(agg_data[x_field].unique().tolist())
        else:
            x_values = sort_with_config(agg_data[x_field].dropna().unique().tolist(), x_field)

        group_values = sort_with_config(agg_data[group_field].dropna().unique().tolist(), group_field)
        pivot_df = agg_data.pivot(index=x_field, columns=group_field, values='ä½œæ¥­æ™‚é–“(h)')
        pivot_df = pivot_df.reindex(index=x_values, columns=group_values).fillna(0.0)
        pivot_df = pivot_df.map(lambda x: f"{x:.1f}")
        pivot_df.index.name = x_axis_label
        pivot_df.columns.name = 'ä½œæ¥­æ™‚é–“[h]'
        return pivot_df


def render_sidebar_overview(placeholder):
    """Render application instructions in the sidebar."""
    placeholder.empty()
    with placeholder.container():
        with st.expander("â„¹ï¸ ä½¿ã„æ–¹ã‚¬ã‚¤ãƒ‰", expanded=False):
            st.markdown(
                "**ï¼œãƒ‡ãƒ¼ã‚¿ç™»éŒ²ï¼**\n"
                "å·¥æ•°ãƒ‡ãƒ¼ã‚¿ã‚’ç™»éŒ²ï¼ˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼‰ã—ã¾ã™ã€‚ï¼’ã¤ã®ç™»éŒ²æ–¹æ³•ãŒã‚ã‚Šã¾ã™ã€‚\n"
                "\n"
                "- æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼šæœˆæ¬¡å·¥æ•°ãƒ‡ãƒ¼ã‚¿ã‚’ï¼‘ã¤ã«ã¾ã¨ã‚ãŸç·å·¥æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç™»éŒ²ã™ã‚‹\n"
                "- æœˆæ¬¡ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆï¼šæ–°ãŸãªæœˆæ¬¡å·¥æ•°ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ã¦ç·å·¥æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°ã—ç™»éŒ²ã™ã‚‹\n"
            )
            st.markdown(
                "**ï¼œå·¥æ•°åˆ†æã‚°ãƒ©ãƒ•ï¼**\n"
                "ç·å·¥æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦æ§˜ã€…ãªåˆ†æã‚°ãƒ©ãƒ•ã‚’ä½œæˆã—ã¾ã™ã€‚ã‚°ãƒ©ãƒ•ä½œæˆã®æ¡ä»¶è¨­å®šã«ã¯ä»¥ä¸‹ã®ã‚‚ã®ãŒã‚ã‚Šã¾ã™ã€‚\n"
                "\n"
                "- ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®šï¼ˆå·¦å´ã®ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ï¼‰ï¼šåˆ†æå¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã‚’çµã‚Šè¾¼ã‚€ã€‚ã€ŒæœŸé–“ã€ã€Œå¤§åˆ†é¡ã€ã€Œä¸­åˆ†é¡ã€ã€Œå€‹äººã€ã€ŒUNITã€ã§ã®çµã‚Šè¾¼ã¿ãŒå¯èƒ½ã€‚\n"
                "- Xè»¸ï¼šXè»¸ã«æ¡ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ç¨®åˆ¥ã‚’é¸æŠã™ã‚‹\n"
                "- ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°æ–¹æ³•ï¼šã‚°ãƒ©ãƒ•ã®å‡¡ä¾‹ï¼ˆç³»åˆ—ï¼‰ã‚’é¸æŠã™ã‚‹\n"
            )


def render_data_status():
    """Show the current dataset status underneath the filter controls."""
    merged_df = st.session_state.get('merged_data')
    st.sidebar.subheader("ãƒ‡ãƒ¼ã‚¿ã®çŠ¶æ…‹")
    if merged_df is not None:
        st.sidebar.markdown(f"ç·ãƒ‡ãƒ¼ã‚¿ä»¶æ•°ï¼š**{len(merged_df):,}**")
        st.sidebar.markdown(f"ç·ä½œæ¥­æ™‚é–“ï¼š**{merged_df['ä½œæ¥­æ™‚é–“(h)'].sum():.1f} h**")
        st.sidebar.caption("ç¾åœ¨ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ç·å·¥æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¦‚è¦ã§ã™ã€‚")
    else:
        st.sidebar.info("ç·å·¥æ•°ãƒ•ã‚¡ã‚¤ãƒ«ãŒã¾ã ç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

st.set_page_config(
    page_title="å·¥æ•°ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("å·¥æ•°åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
st.write("æœˆæ¬¡å·¥æ•°ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã—ã¦å¤šè§’çš„ãªå·¥æ•°åˆ†æã‚’è¡Œã„ã¾ã™")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'merged_data' not in st.session_state:
    st.session_state.merged_data = None

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®è‡ªå‹•èª­ã¿è¾¼ã¿ï¼ˆåˆå›ã®ã¿ï¼‰
if 'default_loaded' not in st.session_state:
    st.session_state.default_loaded = False

if not st.session_state.default_loaded and st.session_state.merged_data is None:
    default_file_path = os.path.join(os.path.dirname(__file__), 'merged_efforts.xlsx')
    if os.path.exists(default_file_path):
        try:
            default_df = pd.read_excel(default_file_path)
            st.session_state.merged_data = default_df
            st.session_state.default_loaded = True
            st.info(f"ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚¡ã‚¤ãƒ« 'merged_efforts.xlsx' ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ ({len(default_df):,}è¡Œ)")
        except Exception as e:
            st.warning(f"ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            st.session_state.default_loaded = True
    else:
        st.session_state.default_loaded = True


sidebar_overview_placeholder = st.sidebar.empty()
render_sidebar_overview(sidebar_overview_placeholder)

st.divider()

tab_data_entry, tab_analysis = st.tabs(["ãƒ‡ãƒ¼ã‚¿ç™»éŒ²", "å·¥æ•°åˆ†æã‚°ãƒ©ãƒ•"])

with tab_data_entry:
    st.header("ãƒ‡ãƒ¼ã‚¿ç™»éŒ²")

    # æ“ä½œãƒ¢ãƒ¼ãƒ‰é¸æŠï¼ˆã‚¿ãƒ–å†…ï¼‰
    upload_mode = st.radio(
        "ç™»éŒ²æ–¹æ³•ã‚’é¸æŠã—ã¦ãã ã•ã„",
        ['æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰', 'æœˆæ¬¡ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆ'],
        index=0,
        horizontal=True,
        key='upload_mode_selector'
    )

    if upload_mode == 'æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰':
        # ========================================
        # ãƒ¢ãƒ¼ãƒ‰1: æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ
        # ========================================
        st.subheader("æ—¢å­˜ã®ç·å·¥æ•°ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")

        analysis_file = st.file_uploader(
            "ç·å·¥æ•°ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=['xlsx'],
            key="analysis_upload"
        )

        if analysis_file:
            try:
                analysis_df = pd.read_excel(analysis_file)
                st.session_state.merged_data = analysis_df
                st.success(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {len(analysis_df):,}è¡Œ")
            except Exception as e:
                st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

    else:
        # ========================================
        # ãƒ¢ãƒ¼ãƒ‰2: æœˆæ¬¡ãƒ‡ãƒ¼ã‚¿çµ±åˆ
        # ========================================
        st.subheader("æœˆæ¬¡å·¥æ•°ãƒ‡ãƒ¼ã‚¿ã®çµ±åˆ")

        with st.expander("ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", expanded=True):
            col1, col2 = st.columns(2)

            with col1:
                st.subheader("æ—¢å­˜ã®ç·å·¥æ•°ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«")
                existing_file = st.file_uploader(
                    "ç·å·¥æ•°ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆæ–°è¦ä½œæˆæ™‚ã¯ä¸è¦ï¼‰",
                    type=['xlsx'],
                    key="existing"
                )

                if existing_file:
                    st.success(f"âœ… {existing_file.name}")
                    try:
                        existing_df = pd.read_excel(existing_file)
                        st.write(f"è¡Œæ•°: {len(existing_df):,}")

                        # å¹´æœˆç¯„å›²è¡¨ç¤º
                        year_month_stats = existing_df.groupby(['å¹´', 'æœˆ']).size().reset_index(name='ä»¶æ•°')
                        st.dataframe(year_month_stats, height=200)
                    except Exception as e:
                        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

            with col2:
                st.subheader("æœˆæ¬¡å·¥æ•°è¨˜éŒ²ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«")
                monthly_files = st.file_uploader(
                    "æœˆæ¬¡å·¥æ•°ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰",
                    type=['xlsx'],
                    accept_multiple_files=True,
                    key="monthly"
                )

                if monthly_files:
                    st.success(f"âœ… {len(monthly_files)}ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠæ¸ˆã¿")
                    for i, file in enumerate(monthly_files, 1):
                        st.write(f"{i}. {file.name}")

        # ãƒãƒ¼ã‚¸å‡¦ç†å®Ÿè¡Œ
        st.divider()

        if monthly_files:
            if st.button("ğŸ”„ ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¸ãƒ»æ¥­å‹™å†…å®¹åˆ†å‰²ã‚’å®Ÿè¡Œ", type="primary"):
                try:
                    progress_bar = st.progress(0.0)
                    status_text = st.empty()

                    def update_progress(progress, status):
                        progress = float(max(0.0, min(1.0, progress)))
                        progress_bar.progress(progress)
                        status_text.text(status)

                    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚¤ãƒ³ã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ
                    if existing_file:
                        existing_file.seek(0)
                    for file in monthly_files:
                        file.seek(0)

                    # ãƒãƒ¼ã‚¸å‡¦ç†å®Ÿè¡Œ
                    final_data = process_multiple_monthly_files(
                        monthly_files,
                        existing_file,
                        progress_callback=update_progress
                    )

                    if final_data is not None:
                        st.session_state.merged_data = final_data

                        st.success("âœ… ãƒãƒ¼ã‚¸ãƒ»æ¥­å‹™å†…å®¹åˆ†å‰²ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

                        # çµ±è¨ˆæƒ…å ±
                        st.subheader("ğŸ“Š çµ±è¨ˆæƒ…å ±")
                        stats = final_data.groupby(['å¹´', 'æœˆ']).agg({
                            'å¾“æ¥­å“¡å': 'nunique',
                            'ä½œæ¥­æ™‚é–“(h)': 'sum'
                        }).reset_index()
                        stats.columns = ['å¹´', 'æœˆ', 'ãƒ¦ãƒ‹ãƒ¼ã‚¯å¾“æ¥­å“¡æ•°', 'ç·ä½œæ¥­æ™‚é–“(h)']
                        st.dataframe(stats)

                        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                        output_buffer = io.BytesIO()
                        final_data.to_excel(output_buffer, index=False, engine='xlsxwriter')
                        output_buffer.seek(0)

                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        filename = f"merged_efforts_{timestamp}.xlsx"

                        st.download_button(
                            label="ğŸ“¥ ç·å·¥æ•°ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=output_buffer,
                            file_name=filename,
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                    else:
                        st.error("âŒ å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ")

                except Exception as e:
                    st.error(f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                    import traceback
                    st.text(traceback.format_exc())
        else:
            st.info("æœˆæ¬¡å·¥æ•°ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„")

render_sidebar_overview(sidebar_overview_placeholder)


with tab_analysis:
    # ========================================
    # å·¥æ•°ãƒ‡ãƒ¼ã‚¿ã®åˆ†ææ©Ÿèƒ½
    # ========================================
    if st.session_state.merged_data is None:
        st.info("ãƒ‡ãƒ¼ã‚¿ã‚’ç™»éŒ²ã—ã¦ãã ã•ã„ã€‚ã€Œãƒ‡ãƒ¼ã‚¿ç™»éŒ²ã€ã‚¿ãƒ–ã§æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‹ã€æœˆæ¬¡ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã—ã¦ãã ã•ã„ã€‚")
    else:
        st.header("å·¥æ•°ãƒ‡ãƒ¼ã‚¿ã®åˆ†æ")

        df = st.session_state.merged_data

        # ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
        df['å¹´'] = pd.to_numeric(df['å¹´'], errors='coerce').astype('Int64')
        df['æœˆ'] = pd.to_numeric(df['æœˆ'], errors='coerce').astype('Int64')
        df['ä½œæ¥­æ™‚é–“(h)'] = pd.to_numeric(df['ä½œæ¥­æ™‚é–“(h)'], errors='coerce')

        # ç„¡åŠ¹ãƒ‡ãƒ¼ã‚¿é™¤å¤–
        df = df[
            (df['å¹´'].notna()) &
            (df['æœˆ'].notna()) &
            (df['ä½œæ¥­æ™‚é–“(h)'] > 0)
        ]

        # ========================================
        # ã‚µã‚¤ãƒ‰ãƒãƒ¼: ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        # ========================================
        st.sidebar.markdown("---")
        st.sidebar.header("ğŸ” ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š")

        # æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼å½¢å¼ï¼‰
        available_year_months = sorted(df[['å¹´', 'æœˆ']].drop_duplicates().values.tolist())
        if available_year_months:
            year_month_labels = [f"{int(y)}-{int(m):02d}" for y, m in available_year_months]
            year_month_datetimes = pd.to_datetime(year_month_labels, format='%Y-%m')
    
            default_end_idx = len(year_month_datetimes) - 1
            default_start_idx = max(0, default_end_idx - 5)  # Last 6 months
    
            start_dt, end_dt = st.sidebar.slider(
                "æœŸé–“",
                min_value=year_month_datetimes[0].to_pydatetime(),
                max_value=year_month_datetimes[-1].to_pydatetime(),
                value=(
                    year_month_datetimes[default_start_idx].to_pydatetime(),
                    year_month_datetimes[default_end_idx].to_pydatetime()
                ),
                format="YYYY-MM",
                key="period_slider"
            )
    
            start_year, start_month = start_dt.year, start_dt.month
            end_year, end_month = end_dt.year, end_dt.month
    
            df_filtered = filter_data_by_period(
                df,
                (start_year, start_month),
                (end_year, end_month)
            )
        else:
            df_filtered = df
            st.sidebar.warning("ãƒ‡ãƒ¼ã‚¿ã«å¹´æœˆæƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“")

        # ã‚°ãƒ­ãƒ¼ãƒãƒ« ä½œæ¥­å¤§åˆ†é¡ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        global_field1_options = ['ã™ã¹ã¦'] + sort_with_config(
            df_filtered['USER_FIELD_01'].dropna().unique().tolist(),
            'USER_FIELD_01'
        )
        global_field1_value = st.sidebar.selectbox(
            "ä½œæ¥­å¤§åˆ†é¡",
            global_field1_options,
            key="global_field1"
        )

        # ã‚°ãƒ­ãƒ¼ãƒãƒ« ä½œæ¥­ä¸­åˆ†é¡ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆcascadingï¼‰
        if global_field1_value != 'ã™ã¹ã¦':
            global_field2_options_filtered = df_filtered[
                df_filtered['USER_FIELD_01'] == global_field1_value
            ]['USER_FIELD_02'].dropna().unique().tolist()
        else:
            global_field2_options_filtered = df_filtered['USER_FIELD_02'].dropna().unique().tolist()

        global_field2_options = ['ã™ã¹ã¦'] + sort_with_config(
            global_field2_options_filtered,
            'USER_FIELD_02'
        )
        global_field2_value = st.sidebar.selectbox(
            "ä½œæ¥­ä¸­åˆ†é¡",
            global_field2_options,
            key="global_field2"
        )

        # ã‚°ãƒ­ãƒ¼ãƒãƒ« å€‹äººãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        global_person_options = ['ã™ã¹ã¦'] + sorted(df_filtered['å¾“æ¥­å“¡å'].dropna().unique().tolist())
        global_person_value = st.sidebar.selectbox(
            "å€‹äºº",
            global_person_options,
            key="global_person"
        )

        # ã‚°ãƒ­ãƒ¼ãƒãƒ« UNITãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        global_unit_options = ['ã™ã¹ã¦'] + sorted(df_filtered['UNIT'].dropna().unique().tolist())
        global_unit_value = st.sidebar.selectbox(
            "UNIT",
            global_unit_options,
            key="global_unit"
        )

        # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
        if global_field1_value != 'ã™ã¹ã¦':
            df_filtered = df_filtered[df_filtered['USER_FIELD_01'] == global_field1_value]
        if global_field2_value != 'ã™ã¹ã¦':
            df_filtered = df_filtered[df_filtered['USER_FIELD_02'] == global_field2_value]
        if global_person_value != 'ã™ã¹ã¦':
            df_filtered = df_filtered[df_filtered['å¾“æ¥­å“¡å'] == global_person_value]
        if global_unit_value != 'ã™ã¹ã¦':
            df_filtered = df_filtered[df_filtered['UNIT'] == global_unit_value]

        st.sidebar.info(f"ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œ: {len(df_filtered):,}ä»¶ / {len(df):,}ä»¶")
        render_data_status()

        # ========================================
        # çµ±åˆãƒãƒ£ãƒ¼ãƒˆè¡¨ç¤º
        # ========================================
#        st.subheader("å·¥æ•°åˆ†æã‚°ãƒ©ãƒ•")

        # æ¥­å‹™å†…å®¹ã‚«ãƒ©ãƒ ã®æ¤œå‡º
        available_business_cols = get_available_business_content_columns(df_filtered)

        # Xè»¸ã¨ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°æ–¹æ³•ã®é¸æŠ
        col1, col2 = st.columns(2)

        with col1:
            # Xè»¸é¸æŠï¼ˆå¹´æœˆã‚’å«ã‚€ï¼‰
            x_axis_options = (
                ['å¹´æœˆ', 'ä½œæ¥­å¤§åˆ†é¡', 'ä½œæ¥­ä¸­åˆ†é¡', 'ä½œæ¥­å°åˆ†é¡', 'å€‹äºº', 'UNIT'] +
                available_business_cols
            )
            x_axis = st.selectbox(
                "Xè»¸",
                x_axis_options,
                key="x_axis"
            )

        with col2:
            # ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°æ–¹æ³•é¸æŠï¼ˆå¹´æœˆã‚’é™¤ãï¼‰
            grouping_options = (
                ['ä½œæ¥­å¤§åˆ†é¡', 'ä½œæ¥­ä¸­åˆ†é¡', 'ä½œæ¥­å°åˆ†é¡', 'å€‹äºº', 'UNIT'] +
                available_business_cols
            )
            grouping = st.selectbox(
                "ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°æ–¹æ³•",
                grouping_options,
                key="grouping"
            )

        # æœŸé–“ãƒ©ãƒ™ãƒ«ä½œæˆ
        if available_year_months:
            period_label = f"{start_year}-{start_month:02d} ã€œ {end_year}-{end_month:02d}"
        else:
            period_label = None

        # ãƒãƒ£ãƒ¼ãƒˆä½œæˆ
        if len(df_filtered) > 0:
            # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã®ãƒãƒƒãƒ”ãƒ³ã‚°
            field_mapping = {
                'å¹´æœˆ': 'å¹´æœˆ',
                'ä½œæ¥­å¤§åˆ†é¡': 'USER_FIELD_01',
                'ä½œæ¥­ä¸­åˆ†é¡': 'USER_FIELD_02',
                'ä½œæ¥­å°åˆ†é¡': 'USER_FIELD_03',
                'å€‹äºº': 'å¾“æ¥­å“¡å',
                'UNIT': 'UNIT'
            }

            # Xè»¸ã¨ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã‚’å–å¾—
            x_field = field_mapping.get(x_axis, x_axis)  # æ¥­å‹™å†…å®¹ã¯ãã®ã¾ã¾
            group_field = field_mapping.get(grouping, grouping)

            # å¹´æœˆåˆ—ã‚’ä½œæˆï¼ˆXè»¸ãŒå¹´æœˆã®å ´åˆï¼‰
            if x_field == 'å¹´æœˆ':
                df_filtered = df_filtered.copy()
                df_filtered['å¹´æœˆ'] = df_filtered['å¹´'].astype(str) + '-' + df_filtered['æœˆ'].astype(str).str.zfill(2)

            # ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°åˆ—ã‚’ä½œæˆï¼ˆã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°ãŒå¹´æœˆã®å¯èƒ½æ€§ã¯ãªã„ãŒå¿µã®ãŸã‚ï¼‰
            if group_field == 'å¹´æœˆ' and 'å¹´æœˆ' not in df_filtered.columns:
                df_filtered = df_filtered.copy()
                df_filtered['å¹´æœˆ'] = df_filtered['å¹´'].astype(str) + '-' + df_filtered['æœˆ'].astype(str).str.zfill(2)

            # ãƒãƒ£ãƒ¼ãƒˆã‚¿ã‚¤ãƒ—ã®æ±ºå®šã¨ä½œæˆ
            from utils.visualization import create_unified_chart

            fig = create_unified_chart(
                df_filtered,
                x_field=x_field,
                group_field=group_field,
                x_axis_label=x_axis,
                grouping_label=grouping,
                range_label=period_label
            )

            st.plotly_chart(fig, use_container_width=True, config=None)

            # ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆæŠ˜ã‚ŠãŸãŸã¿å¼ï¼‰
            with st.expander("ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ï¼šä½œæ¥­æ™‚é–“[h]", expanded=False):
                data_table = create_chart_data_table(
                    df_filtered,
                    x_field=x_field,
                    group_field=group_field,
                    x_axis_label=x_axis,
                    grouping_label=grouping
                )
                st.dataframe(data_table, width='stretch')
        else:
            st.warning("ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
